# ==============================================================================
# API KEY SHARDING (MULTI-ACCOUNT SETUP)
# ==============================================================================
# Use different keys/accounts to bypass rate limits and track costs per capability.
# If specific keys are left blank, the system falls back to OPENROUTER_API_KEY.

# 1. STRATEGY (Dolphin/Llama) - The Manager
STRATEGIC_API_KEY=

# 2. REASONING (DeepSeek R1) - The Brain (Deep Think)
REASONING_API_KEY=

# 3. CODING (Qwen Coder) - The Engineer (Exploits)
CODE_API_KEY=

# 4. VISION (Qwen VL) - The Eyes (Screenshots)
VISUAL_API_KEY=

# GLOBAL FALLBACK (Required if above are empty)
OPENROUTER_API_KEY=

# Optional: Proxy configuration for stealth mode (comma-separated list)
# PROXY_LIST=http://proxy1:port,http://proxy2:port

# ==============================================================================
# LLM MODEL CONFIGURATION
# ==============================================================================
# You can easily change any of these models to use different LLMs from OpenRouter
# Just paste the model identifier and your API key - no need to touch Python code!
# Available models: https://openrouter.ai/models
# ==============================================================================

# Strategic Planning & Triage Model
# Role: Handles high-level decision making, mission planning, triage, scope analysis, and risk assessment
# Default: nousresearch/hermes-3-llama-3.1-70b
STRATEGIC_MODEL=nousresearch/hermes-3-llama-3.1-70b

# Reasoning & Vulnerability Analysis Model
# Role: Specialized in vulnerability analysis, reasoning about exploits, and security assessment
# Default: cognitivecomputations/dolphin3.0-r1-mistral-24b
REASONING_MODEL=cognitivecomputations/dolphin3.0-r1-mistral-24b

# Code Analysis & Payload Engineering Model
# Role: Focuses on analyzing code, generating exploit payloads, writing scripts, and technical implementation
# Default: qwen/qwen-2.5-72b-instruct
CODE_MODEL=qwen/qwen-2.5-72b-instruct

# Visual Analysis & UI Reconnaissance Model (Multimodal)
# Role: Analyzes screenshots to understand UI layouts, identify clickable elements, and detect visual vulnerabilities
# Default: qwen/qwen2.5-vl-32b-instruct:free
VISUAL_MODEL=qwen/qwen2.5-vl-32b-instruct:free

# ==============================================================================
# LLM GENERATION PARAMETERS
# ==============================================================================
# These control the behavior of the LLM responses
# Temperature: Controls randomness (0.0 = deterministic, 1.0 = creative)
# Max Tokens: Maximum length of generated responses
# ==============================================================================

# Default temperature for all models (can be overridden per-call)
# Range: 0.0 to 1.0
# Lower values (0.3-0.5) = more focused and deterministic
# Higher values (0.7-0.9) = more creative and varied
DEFAULT_TEMPERATURE=0.7

# Default maximum tokens to generate
# Controls the maximum length of responses from the LLM
# Higher values allow longer, more detailed responses but cost more
DEFAULT_MAX_TOKENS=4096

# ==============================================================================
# LEGACY COMPATIBILITY (DEPRECATED - Use above variables instead)
# ==============================================================================
# These are kept for backward compatibility but will be removed in future versions
# ORCHESTRATOR_MODEL, CODER_MODEL are mapped to STRATEGIC_MODEL and CODE_MODEL
